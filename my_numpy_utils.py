
# ~~~ Tom Winckelman wrote this; maintained at: https://github.com/ThomasLastName/quality_of_life

import numpy as np

#
# ~~~ Generate 1d training and test data, where lables y are generated by y=f(x)
def generate_random_1d_data( ground_truth, n_train, n_test=1001, a=-1, b=1, noise=0., require_endpoints=True ):
    #
    # ~~~ First, generate the training data
    x_train = np.random.uniform( a, b, n_train-2 if require_endpoints else n_train )
    if require_endpoints:   # in this case, sample 2 fewer points, ane add the two endpoints
        x_train = np.concatenate(( [a], x_train, [b] ))
    assert x_train.size == n_train
    #
    #~~~ Obtain labels by applying the "ground truth" f to x_train, and perhaps also corrupting with noise
    y_train = ground_truth(x_train) + noise*np.random.normal(size=x_train.shape)
    #
    #~~~ Finally, generate the (clean and plentiful) test data
    x_test = np.linspace(a,b,n_test)
    y_test = ground_truth(x_test) 
    return x_train, y_train, x_test, y_test

#
# ~~~ Check whether a matrix has a column of all 1's or not
def test_augmented(X):
    return np.any(np.all(np.isclose(X,1),axis=0))

#
# ~~~ Attach a column of all 1's to a matrix, if there isn't a column of all 1's alreay
def augment(X):
    return X if test_augmented(X) else np.hstack((
            X,
            np.ones( shape=(X.shape[0],1), dtype=X.dtype )  # assumes that X has dtype and shape attributes
        ))

#
# ~~~ Compute the moving average of a list (this reduces the list's length)
def moving_average( list, window_size ):
    kernel = np.ones(window_size) / window_size
    return np.convolve( list, kernel, mode='valid' )


# #
# # ~~~ Entry-wise minimum between vectors (UPDATE: apparently np.minimum(vec1,vec2) does the same)
# def least( vec1, vec2 ):
#     assert isinstance(vec1,np.ndarray) or isinstance(vec2,np.ndarray)
#     if isinstance( vec1, (int,float) ):
#         vec1 = vec1*np.ones_like(vec2)
#     if isinstance( vec2, (int,float) ):
#         vec2 = vec2*np.ones_like(vec1)
#     return np.min( np.vstack((vec1,vec2)).T , axis=-1 )
    
# #
# # ~~~ Entry-wise maximum between vectors (UPDATE: apparently np.maximum(vec1,vec2) does the same)
# def greatest( vec1, vec2 ):
#     assert isinstance(vec1,np.ndarray) or isinstance(vec2,np.ndarray)
#     if isinstance( vec1, (int,float) ):
#         vec1 = vec1*np.ones_like(vec2)
#     if isinstance( vec2, (int,float) ):
#         vec2 = vec2*np.ones_like(vec1)
#     return np.max( np.vstack((vec1,vec2)).T , axis=-1 )
    