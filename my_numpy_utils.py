
# ~~~ Tom Winckelman wrote this; maintained at: https://github.com/ThomasLastName/quality_of_life

import numpy as np

#
# ~~~ Generate 1d training and test data, where lables y are generated by y=f(x)
def generate_random_1d_data( ground_truth, n_train, n_test=1001, a=-1, b=1, noise=0., require_endpoints=True ):
    #
    # ~~~ First, generate the training data
    x_train = np.random.uniform( a, b, n_train-2 if require_endpoints else n_train )
    if require_endpoints:   # in this case, sample 2 fewer points, ane add the two endpoints
        x_train = np.concatenate(( [a], x_train, [b] ))
    assert x_train.size == n_train
    #
    #~~~ Obtain labels by applying the "ground truth" f to x_train, and perhaps also corrupting with noise
    y_train = ground_truth(x_train) + noise*np.random.normal(size=x_train.shape)
    #
    #~~~ Finally, generate the (clean and plentiful) test data
    x_test = np.linspace(a,b,n_test)
    y_test = ground_truth(x_test) 
    return x_train, y_train, x_test, y_test

#
# ~~~ Check whether a matrix has a column of all 1's or not
def test_augmented(X):
    return np.any(np.all(np.isclose(X,1),axis=0))

#
# ~~~ Attach a column of all 1's to a matrix, if there isn't a column of all 1's alreay
def augment(X):
    return X if test_augmented(X) else np.hstack((
            X,
            np.ones( shape=(X.shape[0],1), dtype=X.dtype )  # assumes that X has dtype and shape attributes
        ))

#
# ~~~ Compute the moving average of a list (this reduces the list's length)
moving_average = lambda list, window_size: np.convolve( list, np.ones(window_size) / window_size, mode='valid' )

#
# ~~~ Define a routine that creates the list "H = [(j-th hat function) for j in range(n)]" where n is the length of a sequence of knots
def list_all_the_hat_functions(knots):
    knots = np.sort(knots)
    n = len(knots)
    hat_functions = []
    for j in range(n):
        midpoint = knots[j]
        if j==0:    # ~~~ the "first" one
            next_point = knots[j+1]
            hat_functions.append( 
                    lambda x, b=midpoint, c=next_point: np.maximum( 0, 1-(x-b)/(c-b) )
                )   # ~~~ the positive part of the the line with value 1 at b going down to value 0 at c
        elif j==(n-1):# ~~~ the "last" one
            prior_point = knots[j-1]
            hat_functions.append(
                    lambda x, a=prior_point, b=midpoint: np.maximum( 0, (x-a)/(b-a) )
                )   # ~~~ the positive part of the the line with value 0 at a going up to value 1 at b
        else:
            prior_point = knots[j-1]
            next_point = knots[j+1]
            hat_functions.append(
                    lambda x, a=prior_point, b=midpoint, c=next_point: np.maximum( 0, np.minimum(
                            (x-a) / (b-a),
                        1 - (x-b) / (c-b)
                        ))
                )
    return hat_functions

#
# ~~~ Given a<b<c, define the piece-wise linear hat function which is zero on x<a, which is 1 at x=b, and which is 0 on x>c
assemble_hat_function = lambda a,b,c: list_all_the_hat_functions([a,b,c])[1]

# #
# # ~~~ Entry-wise minimum between vectors (UPDATE: apparently np.minimum(vec1,vec2) does the same)
# def least( vec1, vec2 ):
#     assert isinstance(vec1,np.ndarray) or isinstance(vec2,np.ndarray)
#     if isinstance( vec1, (int,float) ):
#         vec1 = vec1*np.ones_like(vec2)
#     if isinstance( vec2, (int,float) ):
#         vec2 = vec2*np.ones_like(vec1)
#     return np.min( np.vstack((vec1,vec2)).T , axis=-1 )
    
# #
# # ~~~ Entry-wise maximum between vectors (UPDATE: apparently np.maximum(vec1,vec2) does the same)
# def greatest( vec1, vec2 ):
#     assert isinstance(vec1,np.ndarray) or isinstance(vec2,np.ndarray)
#     if isinstance( vec1, (int,float) ):
#         vec1 = vec1*np.ones_like(vec2)
#     if isinstance( vec2, (int,float) ):
#         vec2 = vec2*np.ones_like(vec1)
#     return np.max( np.vstack((vec1,vec2)).T , axis=-1 )
    